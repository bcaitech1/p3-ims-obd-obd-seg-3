# Segmentation Project for NAVER AI BoostCamp 

### ğŸ†Score & Standiing

(Public) 0.6783, 8ë“± 
(private) 0.6574, 9ë“± 
<br/>

# ëª©ì°¨ 

- [File Structure](#file-structure)
- [Simple Use](#simple-use)
  - [Requirements](#requirements)
  - [Install packages](#install-packages)
  - [Train](#train)
  - [Inference](#inference)
- [pipeline](#pipeline)
  - [Data](#data)
  - [Augmentation](#augmentation)
  - [Train](#train)
  - [Modeling](#modeling)
  - [KFold](#kfold)
  - [TTA](#tta)
  - [MultiScale](#multiscale)
  - [Softmax Temperature](#softmax-temperature)
- [Results](#results)
  - [Model](#model)
  - [NMS](#nms)
  - [MultiScale](#multiscale)
- [Environment](#environment)
  - [Hardware](#hardware)
  - [Software](#software)


- [Reference Citation](#reference-citation)

<br/><br/>

## Simple Use

### Install Requirements

```
cd ./MainModel/
pip install -r requirements.txt
```

âœ¨apex should be installed for swin model
```
cd ./SwinModel/
pip install -r requirements.txt
```

### Train
Run each model's ipynb train file

### Inference
Run each model's ipynb inference file

<br/><br/>

## File Structure  
  
```
/
â”‚ 
â”œâ”€â”€ MainModel
â”‚   â”œâ”€â”€ config
â”‚   â”œâ”€â”€ mmdet
â”‚   â”œâ”€â”€ requirements
â”‚   â”œâ”€â”€ faster_rcnn_train.ipynb
â”‚   â”œâ”€â”€ faster_rcnn_inference.ipynb
â”‚   â”œâ”€â”€ faster_rcnn_train_kfold.ipynb
â”‚   â”œâ”€â”€ faster_rcnn_train_mosaic.ipynb
â”‚   â”œâ”€â”€ faster_rcnn_train_ensemble.ipynb
â”‚   â”œâ”€â”€ faster_rcnn_train_psuedo.ipynb
â”‚   â”œâ”€â”€ gflv2_train.ipynb
â”‚   â”œâ”€â”€ gflv2_inference.ipynb
â”‚   â”œâ”€â”€ universenet_train.ipynb
â”‚   â”œâ”€â”€ universenet_inference.ipynb
â”‚   â”œâ”€â”€ vfnet_train.ipynb
â”‚   â”œâ”€â”€ vfnet_inference.ipynb
â”‚   â”œâ”€â”€ detectoRS_train.ipynb
â”‚   â”œâ”€â”€ detectoRS_inference.ipynb
â”‚   â””â”€â”€ requirements
â”‚
â”œâ”€â”€ SwinModel
â”‚   â”œâ”€â”€ apex
â”‚   â”œâ”€â”€ config
â”‚   â”œâ”€â”€ mmdet
â”‚   â”œâ”€â”€ swin_train.ipynb
â”‚   â””â”€â”€ swin_inference.ipynb
â”‚ 
â”œâ”€â”€ README.md
â”œâ”€â”€ pipeline.png
â”œâ”€â”€ __init__.py
```

<br/><br/>

# pipeline

![pipeline](https://github.com/bcaitech1/p3-ims-obd-obd-seg-3/blob/master/detection/pipeline1.png)

#### Data
ë°ì´í„°ëŠ” ìƒìœ„ í´ë” [README](https://github.com/bcaitech1/p3-ims-obd-obd-seg-3/blob/master/README.md)ì— ì •ë¦¬ë˜ì–´ ìˆìŒ.

<br/>

#### Augmentation
- CropNonEmptyMaskIFExists
- GridDistortion
- Flip
- Resize
- GridDropout
- CoarseDropout
- Superpixel
- GridShuffle
- Copy Blob from (https://hoya012.github.io/blog/segmentation_tutorial_pytorch/)
- Cutmix

<br/>

#### kfold
KFold(5 fold)

![kfold](https://static.packt-cdn.com/products/9781789617740/graphics/b04c27c5-7e3f-428a-9aa6-bb3ebcd3584c.png)

KFoldëŠ” ì „ì²´ë°ì´í„°ë¥¼ kê°œ ë‹¨ìœ„ë¡œ ë‚˜ëˆ  ê°ê°ì„ Trainê³¼ Validationì— ì‚¬ìš©í•˜ëŠ” ê¸°ë²•ìœ¼ë¡œ ì£¼ì–´ì§„ ë°ì´í„° ì „ì²´ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. íŠ¹íˆ ì´ë²ˆ ëŒ€íšŒì™€ ê°™ì´ ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²½ìš° ë„ì›€ì´ ëœë‹¤. ì´ë¯¸ì§€ì™€ í´ë˜ìŠ¤ ë³„ annotationì´ 5ê°œì˜ í´ë“œì— ê³¨ê³ ë£¨ ë“¤ì–´ê°€ë„ë¡ í–ˆëŠ”ë°, ì´ë¯¸ì§€ë§ˆë‹¤ ë“¤ì–´ìˆëŠ” annotationì˜ ê°¯ìˆ˜ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ìµœëŒ€í•œ ê³µí‰í•˜ê²Œ ë°ì´í„°ë¥¼ ë‚˜ëˆ„ëŠ” ë¶€ë¶„ì— ì–´ë ¤ì›€ì´ ìˆì—ˆë‹¤. 5 foldë¡œ ë‚˜ëˆˆ ì´ìœ ëŠ” ë°ì´í„°ê°€ ê°€ì¥ ì ì€ Batteryë¥¼ ê¸°ì¤€ìœ¼ë¡œ 5ê°œì˜  foldì— ì´ë¯¸ì§€ì™€ í•¨ê»˜ annotationì„ ê°€ì¥ ê³¨ê³ ë£¨ ë‚˜ëˆŒ ìˆ˜ ìˆëŠ” ìˆ˜ì¹˜ê°€ 5ë¼ê³  íŒë‹¨í•˜ì˜€ê¸° ë•Œë¬¸ì´ë‹¤.

<br/>


#### Loss

- Cross Entropy Loss
- Weighted Cross Entropy Loss
- Dice Loss + Cross Entropy Loss
- Lovasz Loss
- Lovasz Loss + Cross Entropy Loss
- ReduceLROnPlateau Scheduler

<br/>

#### SWA Scheduler
train í•™ìŠµì´ ë” ì´ìƒ ë˜ì§€ ì•Šì•˜ë˜ 18epoch ~ 20epoch SWA optimizerë¥¼ ì‚¬ìš©í•˜ì—¬ test error ìµœì†Œë¡œ weightê°€ ë˜ë„ë¡ ì ìš©í•˜ì˜€ë‹¤.
ì‹¤ì œ SWA ì ìš© ê²°ê³¼ Leader board score í•˜ë½í•˜ì—¬ ìµœì¢… ëª¨ë¸ì—ëŠ” ì ìš©í•˜ì§€ ì•Šì•˜ë‹¤.
<br/>

#### Modeling

| Method                 | mAP       |
|------------------------|:---------:|
| GSCNN            |  0.43 
| EfficientNet b5             |  0.44    |
| EfficientNet b0           |  0.4805
| EfficientNet b4           |  0.4848    
| EfficientNet b7               |  0.49    
| RegNetY 320                |  0.5336 
| FCN8s            |  0.54    
| TransUNet            |  0.5445    
| HR+OCR Net           |   0.5453    
| augmented + UniverseNet + multi scale train            |  0.5820    

<br/>

#### TTA(Augmentation)
- Horizontal Flip
- Random Brightness contrast


<br/>

#### TTA(MultiScale)

DeeplabV3+ Efficientnet-b5 20epoch ê¸°ì¤€

| Scale                |   weight      |    mAP    |
|-----------------------|:-------------:|:---------:|
|  Single Scale(512)   |    1   |  0.6121 |         
|  3 Multi Scale(256, 512, 1024)   | 0.3:0.3:0.3 | 0.6337 |
|  3 Multi Scale(256, 512, 1024)   | 0.3:0.4:0.3 | 0.6342 |
|  3 Multi Scale(256, 512, 1024)   | 0.3:0.5:0.3 | 0.6318 |
|  5 Multi Scale(128, 256, 512, 768, 1024)   | 0.2:0.2:0.2:0.2:0.2 | 0.6213 |
|  5 Multi Scale(128, 256, 512, 768, 1024)   | 0.15:0.2:0.3:0.2:0.15 | 0.6219 |


<br/>

#### Softmax Temperature
soft voting ensembel íš¨ê³¼ë¥¼ ê·¹ëŒ€í™” í•˜ê¸°ìœ„í•´ softmax Temperatureë¥¼ ì ìš©í•˜ì˜€ë‹¤.
ìµœì¢… ì œì¶œ ì‹œ Leader board score í•˜ë½(0.6783 -> 0.6765)í•˜ì—¬ ìµœì¢… ëª¨ë¸ì— ì ìš©í•˜ì§€ ì•Šì•˜ë‹¤.

<br/>

#### Ensemble

| Method                |    model weight      |    mAP    |
|-----------------------|:-------------:|:---------:|
|  GFLv2, VFNe, UniversNnet   |    0.5:0.5:0.5   |  0.6048 |         
|  GFLv2, VFNet, UniverseNet Swin   | 0.5:0.5:0.5:0.5 | 0.5993 


<br/><br/>

## Environment

We trained models on our lab's Linux cluster. The environment listed below reflects a typical software / hardware configuration in this cluster.

#### Hardware:
- CPU: Xeon Gold 5120
- GPU: Tesla V100, P40
- Mem: > 90GB
- Data is stored in remote server stroage.

#### Software:
- System: Ubuntu 18.04.4 LTS with Linux 4.4.0-210-generic kernel.
- Python: 3.7 distributed by Anaconda.
- CUDA: 10.1

<br/><br/>

# Results

âœ¨best performamce of each model

| Method                 | mAP       |  config  |  pretrained 
|------------------------|:---------:|:--------:|:---------:
| augmented + GFL v2 + multi scale train                |  0.5706    |  config   |  pretrained 
| vfnet r2 101 + multi scale train + SWA + WS + GN            |  0.5608    |  config   |  pretrained 
| augmented + UniverseNet + multi scale train            |  0.5820    |  config   |  pretrained 


<br/><br/>

## Reference/ Citation

[1] mmdetection <br/>
@article{mmdetection,
  title   = {{MMDetection}: Open MMLab Detection Toolbox and Benchmark},
  author  = {Chen, Kai and Wang, Jiaqi and Pang, Jiangmiao and Cao, Yuhang and
             Xiong, Yu and Li, Xiaoxiao and Sun, Shuyang and Feng, Wansen and
             Liu, Ziwei and Xu, Jiarui and Zhang, Zheng and Cheng, Dazhi and
             Zhu, Chenchen and Cheng, Tianheng and Zhao, Qijie and Li, Buyu and
             Lu, Xin and Zhu, Rui and Wu, Yue and Dai, Jifeng and Wang, Jingdong
             and Shi, Jianping and Ouyang, Wanli and Loy, Chen Change and Lin, Dahua},
  journal= {arXiv preprint arXiv:1906.07155},
  year={2019}
}<br/>
[2] [GFL v2 & UniverseNet](https://github.com/shinya7y/UniverseNet)<br/>
